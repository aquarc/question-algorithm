{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cbed3840",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-04-08T02:48:32.435792Z",
     "iopub.status.busy": "2025-04-08T02:48:32.435330Z",
     "iopub.status.idle": "2025-04-08T02:48:33.310440Z",
     "shell.execute_reply": "2025-04-08T02:48:33.309116Z"
    },
    "papermill": {
     "duration": 0.885084,
     "end_time": "2025-04-08T02:48:33.312353",
     "exception": false,
     "start_time": "2025-04-08T02:48:32.427269",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31432e41",
   "metadata": {
    "papermill": {
     "duration": 0.005691,
     "end_time": "2025-04-08T02:48:33.324443",
     "exception": false,
     "start_time": "2025-04-08T02:48:33.318752",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Some parts of this Codelab are (c) Google 2025 under the Apache License.\n",
    "(c) Aquarc 2025"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96649ba7",
   "metadata": {
    "papermill": {
     "duration": 0.005674,
     "end_time": "2025-04-08T02:48:33.336142",
     "exception": false,
     "start_time": "2025-04-08T02:48:33.330468",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Synopsis\n",
    "Aquarc is an all-in-one SAT platform for high schoolers designed to minimize time spent using the software and maximizing practice and essential questions. In order to further this mission, Aquarc Intelligence was created to analyze mistakes within a question and to suggest similar questions for efficient practicing."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9fa74ea",
   "metadata": {
    "papermill": {
     "duration": 0.005647,
     "end_time": "2025-04-08T02:48:33.347886",
     "exception": false,
     "start_time": "2025-04-08T02:48:33.342239",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Install the SDK \n",
    "We will be using Google's Gemini and utilities to build the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "63608d81",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-08T02:48:33.361756Z",
     "iopub.status.busy": "2025-04-08T02:48:33.361275Z",
     "iopub.status.idle": "2025-04-08T02:49:19.385129Z",
     "shell.execute_reply": "2025-04-08T02:49:19.383802Z"
    },
    "papermill": {
     "duration": 46.03312,
     "end_time": "2025-04-08T02:49:19.387187",
     "exception": false,
     "start_time": "2025-04-08T02:48:33.354067",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.3/67.3 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\r\n",
      "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\r\n",
      "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m144.7/144.7 kB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m21.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m232.6/232.6 kB\u001b[0m \u001b[31m12.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.3/18.3 MB\u001b[0m \u001b[31m83.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.4/2.4 MB\u001b[0m \u001b[31m60.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m94.9/94.9 kB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m100.9/100.9 kB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m284.2/284.2 kB\u001b[0m \u001b[31m15.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m62.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m423.3/423.3 kB\u001b[0m \u001b[31m22.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.2/99.2 kB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.0/16.0 MB\u001b[0m \u001b[31m79.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m55.9/55.9 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m183.4/183.4 kB\u001b[0m \u001b[31m10.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m65.2/65.2 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m118.9/118.9 kB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m85.0/85.0 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.3/62.3 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m442.1/442.1 kB\u001b[0m \u001b[31m25.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m319.7/319.7 kB\u001b[0m \u001b[31m16.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.5/71.5 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.8/3.8 MB\u001b[0m \u001b[31m79.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m452.9/452.9 kB\u001b[0m \u001b[31m23.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25h  Building wheel for pypika (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\r\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\r\n",
      "gcsfs 2024.10.0 requires fsspec==2024.10.0, but you have fsspec 2024.12.0 which is incompatible.\r\n",
      "google-api-core 1.34.1 requires protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<4.0.0dev,>=3.19.5, but you have protobuf 5.29.4 which is incompatible.\r\n",
      "google-cloud-bigtable 2.27.0 requires google-api-core[grpc]<3.0.0dev,>=2.16.0, but you have google-api-core 1.34.1 which is incompatible.\r\n",
      "google-cloud-translate 3.12.1 requires protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.19.5, but you have protobuf 5.29.4 which is incompatible.\r\n",
      "pandas-gbq 0.25.0 requires google-api-core<3.0.0dev,>=2.10.2, but you have google-api-core 1.34.1 which is incompatible.\r\n",
      "tensorflow 2.17.1 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3, but you have protobuf 5.29.4 which is incompatible.\r\n",
      "tensorflow-decision-forests 1.10.0 requires tensorflow==2.17.0, but you have tensorflow 2.17.1 which is incompatible.\r\n",
      "tensorflow-metadata 1.13.1 requires protobuf<5,>=3.20.3, but you have protobuf 5.29.4 which is incompatible.\u001b[0m\u001b[31m\r\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip uninstall -qqy jupyterlab  # Remove unused packages from Kaggle's base image that conflict\n",
    "!pip install -U -q \"google-genai==1.7.0\" langchain PyPDF2 chromadb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b70d1f08",
   "metadata": {
    "papermill": {
     "duration": 0.007972,
     "end_time": "2025-04-08T02:49:19.404659",
     "exception": false,
     "start_time": "2025-04-08T02:49:19.396687",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Import the SDK and set up the API key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "724394f7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-08T02:49:19.422485Z",
     "iopub.status.busy": "2025-04-08T02:49:19.422118Z",
     "iopub.status.idle": "2025-04-08T02:49:20.677344Z",
     "shell.execute_reply": "2025-04-08T02:49:20.676413Z"
    },
    "papermill": {
     "duration": 1.266419,
     "end_time": "2025-04-08T02:49:20.679265",
     "exception": false,
     "start_time": "2025-04-08T02:49:19.412846",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from google import genai\n",
    "from google.genai import types\n",
    "\n",
    "from IPython.display import HTML, Markdown, display"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e259c782",
   "metadata": {
    "papermill": {
     "duration": 0.008309,
     "end_time": "2025-04-08T02:49:20.696028",
     "exception": false,
     "start_time": "2025-04-08T02:49:20.687719",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Set up a retry helper so we can press \"Run All\" and not worry about hitting the quota. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2c98cfba",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-08T02:49:20.714119Z",
     "iopub.status.busy": "2025-04-08T02:49:20.713551Z",
     "iopub.status.idle": "2025-04-08T02:49:20.885216Z",
     "shell.execute_reply": "2025-04-08T02:49:20.884211Z"
    },
    "papermill": {
     "duration": 0.182779,
     "end_time": "2025-04-08T02:49:20.886996",
     "exception": false,
     "start_time": "2025-04-08T02:49:20.704217",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from google.api_core import retry\n",
    "\n",
    "\n",
    "is_retriable = lambda e: (isinstance(e, genai.errors.APIError) and e.code in {429, 503})\n",
    "\n",
    "genai.models.Models.generate_content = retry.Retry(\n",
    "    predicate=is_retriable)(genai.models.Models.generate_content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd1c8154",
   "metadata": {
    "papermill": {
     "duration": 0.008136,
     "end_time": "2025-04-08T02:49:20.903699",
     "exception": false,
     "start_time": "2025-04-08T02:49:20.895563",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Set up your API key\n",
    "\n",
    "To run the following cell, your API key must be stored it in a [Kaggle secret](https://www.kaggle.com/discussions/product-feedback/114053) named `GOOGLE_API_KEY`.\n",
    "\n",
    "If you don't already have an API key, you can grab one from [AI Studio](https://aistudio.google.com/app/apikey). You can find [detailed instructions in the docs](https://ai.google.dev/gemini-api/docs/api-key).\n",
    "\n",
    "To make the key available through Kaggle secrets, choose `Secrets` from the `Add-ons` menu and follow the instructions to add your key or enable it for this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ec2bd7d5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-08T02:49:20.921719Z",
     "iopub.status.busy": "2025-04-08T02:49:20.921213Z",
     "iopub.status.idle": "2025-04-08T02:49:21.011430Z",
     "shell.execute_reply": "2025-04-08T02:49:21.010403Z"
    },
    "papermill": {
     "duration": 0.101288,
     "end_time": "2025-04-08T02:49:21.013365",
     "exception": false,
     "start_time": "2025-04-08T02:49:20.912077",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from kaggle_secrets import UserSecretsClient\n",
    "\n",
    "GOOGLE_API_KEY = UserSecretsClient().get_secret(\"GOOGLE_API_KEY\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "027af53a",
   "metadata": {
    "papermill": {
     "duration": 0.008169,
     "end_time": "2025-04-08T02:49:21.030159",
     "exception": false,
     "start_time": "2025-04-08T02:49:21.021990",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Choose your model\n",
    "Depending on what's available and your quota, choose a model that's effective for your purposes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "33843082",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-08T02:49:21.048113Z",
     "iopub.status.busy": "2025-04-08T02:49:21.047645Z",
     "iopub.status.idle": "2025-04-08T02:49:21.467846Z",
     "shell.execute_reply": "2025-04-08T02:49:21.466454Z"
    },
    "papermill": {
     "duration": 0.431201,
     "end_time": "2025-04-08T02:49:21.469599",
     "exception": false,
     "start_time": "2025-04-08T02:49:21.038398",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "models/chat-bison-001\n",
      "models/text-bison-001\n",
      "models/embedding-gecko-001\n",
      "models/gemini-1.0-pro-vision-latest\n",
      "models/gemini-pro-vision\n",
      "models/gemini-1.5-pro-latest\n",
      "models/gemini-1.5-pro-001\n",
      "models/gemini-1.5-pro-002\n",
      "models/gemini-1.5-pro\n",
      "models/gemini-1.5-flash-latest\n",
      "models/gemini-1.5-flash-001\n",
      "models/gemini-1.5-flash-001-tuning\n",
      "models/gemini-1.5-flash\n",
      "models/gemini-1.5-flash-002\n",
      "models/gemini-1.5-flash-8b\n",
      "models/gemini-1.5-flash-8b-001\n",
      "models/gemini-1.5-flash-8b-latest\n",
      "models/gemini-1.5-flash-8b-exp-0827\n",
      "models/gemini-1.5-flash-8b-exp-0924\n",
      "models/gemini-2.5-pro-exp-03-25\n",
      "models/gemini-2.5-pro-preview-03-25\n",
      "models/gemini-2.0-flash-exp\n",
      "models/gemini-2.0-flash\n",
      "models/gemini-2.0-flash-001\n",
      "models/gemini-2.0-flash-exp-image-generation\n",
      "models/gemini-2.0-flash-lite-001\n",
      "models/gemini-2.0-flash-lite\n",
      "models/gemini-2.0-flash-lite-preview-02-05\n",
      "models/gemini-2.0-flash-lite-preview\n",
      "models/gemini-2.0-pro-exp\n",
      "models/gemini-2.0-pro-exp-02-05\n",
      "models/gemini-exp-1206\n",
      "models/gemini-2.0-flash-thinking-exp-01-21\n",
      "models/gemini-2.0-flash-thinking-exp\n",
      "models/gemini-2.0-flash-thinking-exp-1219\n",
      "models/learnlm-1.5-pro-experimental\n",
      "models/gemma-3-1b-it\n",
      "models/gemma-3-4b-it\n",
      "models/gemma-3-12b-it\n",
      "models/gemma-3-27b-it\n",
      "models/embedding-001\n",
      "models/text-embedding-004\n",
      "models/gemini-embedding-exp-03-07\n",
      "models/gemini-embedding-exp\n",
      "models/aqa\n",
      "models/imagen-3.0-generate-002\n"
     ]
    }
   ],
   "source": [
    "client = genai.Client(api_key=GOOGLE_API_KEY)\n",
    "\n",
    "for model in client.models.list():\n",
    "  print(model.name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1220d54",
   "metadata": {
    "papermill": {
     "duration": 0.008191,
     "end_time": "2025-04-08T02:49:21.486298",
     "exception": false,
     "start_time": "2025-04-08T02:49:21.478107",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Check out the detailed information for your model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "11015024",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-08T02:49:21.504136Z",
     "iopub.status.busy": "2025-04-08T02:49:21.503751Z",
     "iopub.status.idle": "2025-04-08T02:49:21.571498Z",
     "shell.execute_reply": "2025-04-08T02:49:21.570461Z"
    },
    "papermill": {
     "duration": 0.078589,
     "end_time": "2025-04-08T02:49:21.573189",
     "exception": false,
     "start_time": "2025-04-08T02:49:21.494600",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'name': 'models/gemini-2.0-flash', 'display_name': 'Gemini 2.0 Flash', 'description': 'Gemini 2.0 Flash', 'version': '2.0', 'tuned_model_info': {}, 'input_token_limit': 1048576, 'output_token_limit': 8192, 'supported_actions': ['generateContent', 'countTokens']}\n"
     ]
    }
   ],
   "source": [
    "for model in client.models.list():\n",
    "  if model.name == 'models/gemini-2.0-flash':\n",
    "    print(model.to_json_dict())\n",
    "    break\n",
    "\n",
    "# change this line if you want to use a different model\n",
    "model = \"gemini-2.0-flash\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa70b38c",
   "metadata": {
    "papermill": {
     "duration": 0.008135,
     "end_time": "2025-04-08T02:49:21.589740",
     "exception": false,
     "start_time": "2025-04-08T02:49:21.581605",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Test your model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e6a93cde",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-08T02:49:21.607434Z",
     "iopub.status.busy": "2025-04-08T02:49:21.607084Z",
     "iopub.status.idle": "2025-04-08T02:49:22.017027Z",
     "shell.execute_reply": "2025-04-08T02:49:22.015898Z"
    },
    "papermill": {
     "duration": 0.420835,
     "end_time": "2025-04-08T02:49:22.018732",
     "exception": false,
     "start_time": "2025-04-08T02:49:21.597897",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello Zlork! It's nice to meet you. How can I help you today?\n",
      "\n"
     ]
    }
   ],
   "source": [
    "chat = client.chats.create(model=model, history=[])\n",
    "response = chat.send_message('Hello! My name is Zlork.')\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56ef186a",
   "metadata": {
    "papermill": {
     "duration": 0.008176,
     "end_time": "2025-04-08T02:49:22.035586",
     "exception": false,
     "start_time": "2025-04-08T02:49:22.027410",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "You can use the `Markdown()` function to format it nicely in Kaggle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "37ad8358",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-08T02:49:22.053681Z",
     "iopub.status.busy": "2025-04-08T02:49:22.053346Z",
     "iopub.status.idle": "2025-04-08T02:49:22.925062Z",
     "shell.execute_reply": "2025-04-08T02:49:22.924052Z"
    },
    "papermill": {
     "duration": 0.882723,
     "end_time": "2025-04-08T02:49:22.926742",
     "exception": false,
     "start_time": "2025-04-08T02:49:22.044019",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Greetings, Zlork! It is with great pleasure that I extend a digital hand in welcome.\n",
       "\n",
       "I hope the digital realm finds you well.\n",
       "\n",
       "May I inquire as to how I can be of assistance to you this day?\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = chat.send_message('Hello! My name is Zlork.' + \n",
    "                             'Use some fancy markdown in your message')\n",
    "Markdown(response.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42292ae9",
   "metadata": {
    "papermill": {
     "duration": 0.008268,
     "end_time": "2025-04-08T02:49:22.943713",
     "exception": false,
     "start_time": "2025-04-08T02:49:22.935445",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# A fine prompt\n",
    "**TODO: you should probably move this**\n",
    "\n",
    "Let's start by writing our prompt. What should it include and what should it mention? Following the principles taught throughout the course, let's place an importance on giving **positive** instructions rather than **negative** instructions to maintain effectiveness. \n",
    "\n",
    "The model needs to do the following:\n",
    "- Stick to the SAT: Understand weighting and importance of certain questions, categories, and ensure all advice is applicable to the bounds of the SAT. A document with the specifications of the SAT format can be used for Retrieval Augmented Generation (RAG) rather than potential hallucination over the exact requirements.\n",
    "- Have access to the current question (and maybe the previous questions for even more context)\n",
    "- Have access to the answers and time between each to estimate confidence.\n",
    "- Understand images or SVGs for Inference and other Reading/Writing questions.\n",
    "- Use Tree of Thoughts (ToT) to generate multiple solving processes because multiple methods may be used to arrive at the same answer, and output these answering mechanisms in a JSON array to present on the website effectively (a TUI for this notebook)\n",
    "- Find semantically related questions and present them to the user on the website using ReAct (a TUI for this notebook)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e55f5a5d",
   "metadata": {
    "papermill": {
     "duration": 0.008284,
     "end_time": "2025-04-08T02:49:22.960486",
     "exception": false,
     "start_time": "2025-04-08T02:49:22.952202",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Let's start by finding an effective prompt. \n",
    "Then we can evaluate the effectiveness of including the SAT standards in a PDF to help the user answering a question. We will also evaluate whether a vector search database is useful for this document.\n",
    "\n",
    "Below, the variables for the specific question we are testing are defined."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "67e4db0a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-08T02:49:22.978758Z",
     "iopub.status.busy": "2025-04-08T02:49:22.978419Z",
     "iopub.status.idle": "2025-04-08T02:49:22.983345Z",
     "shell.execute_reply": "2025-04-08T02:49:22.982330Z"
    },
    "papermill": {
     "duration": 0.016105,
     "end_time": "2025-04-08T02:49:22.984984",
     "exception": false,
     "start_time": "2025-04-08T02:49:22.968879",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# All questions are (c) CollegeBoard 2025.\n",
    "question = \"\"\"\n",
    "In a paper about p-i-n planar perovskite solar cells (one of several perovskite cell architectures designed to collect and store solar power), Lyndsey McMillon-Brown et al. described a method for fabricating the cell’s electronic transport layer (ETL) using a spray coating. Conventional ETL fabrication is accomplished using a solution of nanoparticles. The process can result in a loss of up to 80% of the solution, increasing the cost of manufacturing at scale—an issue that may be obviated by spray coating fabrication, which the researchers describe as “highly reproducible, concise, and practical.”\n",
    "\n",
    "What does the text most strongly suggest about conventional ETL fabrication?\n",
    "A. It is less suitable for manufacturing large volumes of planar p-i-n perovskite solar cells than an alternative fabrication method may be.\n",
    "B. It is more expensive when manufacturing at scale than are processes for fabricating ETLs used in other perovskite solar cell architectures.\n",
    "C. It typically entails a greater loss of nanoparticle solution than do other established approaches for ETL fabrication.\n",
    "D. It is somewhat imprecise and therefore limits the potential effectiveness of p-i-n planar perovskite solar cells at capturing and storing solar power.\n",
    "\"\"\"\n",
    "\n",
    "rationale = \"\"\"\n",
    "Choice A is the best answer. Conventional solar cell fabrication increases “the cost of manufacturing at scale,” but spray coating might get rid of that problem.\n",
    "\n",
    "Choice B is incorrect. This is not completely supported by the text. While it’s true that conventional ETL fabrication is expensive at scale, there’s nothing in the text that mentions other perovskite solar cell architectures. Choice C is incorrect. This choice does not match the text. Only one conventional method of ETL fabrication is described, so we can’t compare the solution loss in this method to that of other conventional methods. Choice D is incorrect. This choice isn’t supported by the text. The text never suggests that the effectiveness of solar cells changes based on their method of fabrication. \n",
    "\"\"\"\n",
    "\n",
    "user_answer = \"C\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66832e57",
   "metadata": {
    "papermill": {
     "duration": 0.008373,
     "end_time": "2025-04-08T02:49:23.002310",
     "exception": false,
     "start_time": "2025-04-08T02:49:22.993937",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Ideally, the user will talk to the chatbot after it gets the question wrong (or before in some scenarios, too). Either way, the user will have some rationale as to his or her answer to the question. Don't expect this rationale to be well thought out - the objective of the intelligent agent is to draw out what they actually mean. It may be completely omitted as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e51d0bf7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-08T02:49:23.020480Z",
     "iopub.status.busy": "2025-04-08T02:49:23.020141Z",
     "iopub.status.idle": "2025-04-08T02:49:23.024084Z",
     "shell.execute_reply": "2025-04-08T02:49:23.023117Z"
    },
    "papermill": {
     "duration": 0.015015,
     "end_time": "2025-04-08T02:49:23.025773",
     "exception": false,
     "start_time": "2025-04-08T02:49:23.010758",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "user_rationale = \"Isn't the new method of ETL fabrication the same as the 'established methods'\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "900929ac",
   "metadata": {
    "papermill": {
     "duration": 0.00835,
     "end_time": "2025-04-08T02:49:23.042865",
     "exception": false,
     "start_time": "2025-04-08T02:49:23.034515",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Synthesize the prompt:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4e579458",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-08T02:49:23.060943Z",
     "iopub.status.busy": "2025-04-08T02:49:23.060611Z",
     "iopub.status.idle": "2025-04-08T02:49:26.221724Z",
     "shell.execute_reply": "2025-04-08T02:49:26.220768Z"
    },
    "papermill": {
     "duration": 3.172025,
     "end_time": "2025-04-08T02:49:26.223339",
     "exception": false,
     "start_time": "2025-04-08T02:49:23.051314",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Thanks for your question! I can definitely understand why you chose answer C. Let's take a closer look.\n",
       "\n",
       "**SAT Reading: Command of Evidence (Inference)**\n",
       "\n",
       "*   **Skill Tested:** This question asks you to make an inference based on what the passage suggests. It falls under \"command of evidence,\" as you need to find the textual basis for your answer.\n",
       "*   **Why Choice C is Incorrect:** The passage *contrasts* the conventional method with the spray coating method. The passage says the conventional method \"can result in a loss of up to 80% of the solution.\" It *implies* the spray-coating method is better, but it *doesn't* give information about other \"established approaches for ETL fabrication.\" We only know about the conventional method using nanoparticle solution.\n",
       "*   **Why Choice A is Correct:** The passage explicitly states the conventional method increases \"the cost of manufacturing at scale.\" It *suggests* the spray coating method \"may obviate\" this issue. \"Obviate\" means to remove or make unnecessary. Thus, the passage implies the conventional method is *less* suitable for large-scale manufacturing than the spray coating method.\n",
       "\n",
       "**Improvement Strategy**\n",
       "\n",
       "1.  **Focus on Explicit Comparisons:** When a question asks you to compare, make sure the comparison is explicitly stated or strongly implied in the text.\n",
       "2.  **Avoid Assumptions:** Don't assume information that isn't directly provided. Choice C requires you to assume that the conventional method described *is* one of the \"other established approaches,\" which is not stated.\n",
       "3.  **Pay Attention to Qualifying Language:** Notice words like \"may,\" \"might,\" \"suggests.\" These indicate inferences, not direct statements.\n",
       "\n",
       "I hope this helps clarify the question! Let me know if you have any further questions.\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from google.genai.types import GenerateContentConfig\n",
    "\n",
    "response = client.models.generate_content(\n",
    "    model=\"gemini-2.0-flash-001\",\n",
    "    # no specs yet\n",
    "    contents=f\"{question} {rationale}\\n The user got: {user_answer}\\n {user_rationale}\",\n",
    "    config=GenerateContentConfig(\n",
    "        system_instruction=[\n",
    "            \"You are an SAT expert tutor. Analyze questions using the official SAT framework. \",\n",
    "            \"Help students by:\\n\",\n",
    "            \"1. Identifying question type and skills tested\\n\",\n",
    "            \"2. Explaining why answers are correct/incorrect\\n\",\n",
    "            \"3. Providing actionable improvement strategies\\n\",\n",
    "            \"Use formal but friendly language. Reference the SAT specs when possible.\",\n",
    "        ]\n",
    "    ),\n",
    ")\n",
    "\n",
    "\n",
    "Markdown(response.text)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ffe4f36",
   "metadata": {
    "papermill": {
     "duration": 0.008441,
     "end_time": "2025-04-08T02:49:26.240508",
     "exception": false,
     "start_time": "2025-04-08T02:49:26.232067",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Perhaps the model will be more effective with FAISS vector database searches for the PDF.\n",
    "\n",
    "# Parse PDF\n",
    "The following code uses lossy conversion to turn the PDF into readable text."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15890e18",
   "metadata": {
    "papermill": {
     "duration": 0.008396,
     "end_time": "2025-04-08T02:49:26.257511",
     "exception": false,
     "start_time": "2025-04-08T02:49:26.249115",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Information like tables and images will be lost in the process, as demonstrated by the following snippet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0ec30c36",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-08T02:49:26.275849Z",
     "iopub.status.busy": "2025-04-08T02:49:26.275520Z",
     "iopub.status.idle": "2025-04-08T02:49:26.907399Z",
     "shell.execute_reply": "2025-04-08T02:49:26.906067Z"
    },
    "papermill": {
     "duration": 0.64302,
     "end_time": "2025-04-08T02:49:26.909093",
     "exception": false,
     "start_time": "2025-04-08T02:49:26.266073",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example table  \n",
      "This is an example of a data table. \n",
      "Disability \n",
      "Category Participants  Ballots \n",
      "Completed  Ballots \n",
      "Incomplete/  \n",
      "Terminated  Results  \n",
      "Accuracy  Time to \n",
      "complete \n",
      "Blind  5 1 4 34.5%, n=1  1199 sec, n=1  \n",
      "Low Vision  5 2 3 98.3% n=2  \n",
      "(97.7%, n=3)  1716 sec, n=3  \n",
      "(1934 sec, n=2)  \n",
      "Dexterity  5 4 1 98.3%, n=4  1672.1 sec, n=4  \n",
      "Mobility  3 3 0 95.4%, n=3  1416 sec, n=3  \n",
      " \n"
     ]
    }
   ],
   "source": [
    "from PyPDF2 import PdfReader\n",
    "from io import BytesIO\n",
    "import requests\n",
    "\n",
    "url = \"https://www.w3.org/WAI/WCAG20/Techniques/working-examples/PDF20/table.pdf\"\n",
    "response = requests.get(url)\n",
    "pdf_bytes = BytesIO(response.content)\n",
    "\n",
    "text = \"\"\n",
    "pdf_reader = PdfReader(pdf_bytes)\n",
    "for page in pdf_reader.pages:\n",
    "    text += page.extract_text()\n",
    "\n",
    "print(text[0:1000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4db52e62",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-08T02:49:26.928146Z",
     "iopub.status.busy": "2025-04-08T02:49:26.927729Z",
     "iopub.status.idle": "2025-04-08T02:49:32.647233Z",
     "shell.execute_reply": "2025-04-08T02:49:32.646096Z"
    },
    "papermill": {
     "duration": 5.730998,
     "end_time": "2025-04-08T02:49:32.649004",
     "exception": false,
     "start_time": "2025-04-08T02:49:26.918006",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class '_io.BytesIO'>\n",
      "Assessment Framework \n",
      "for the Digital SAT® SuiteAssessment Framework \n",
      "for the Digital SAT® Suite\n",
      "Version 3.01, August 2024\n",
      "About College Board\n",
      "College Board reaches more than 7 million students a year, helping them \n",
      "navigate the path from high school to college and career. Our not-for-\n",
      "profit membership organization was founded more than 120 years ago. \n",
      "We pioneered programs like the SAT® and AP® to expand opportunities \n",
      "for students and help them develop the skills they need. Our BigFuture® \n",
      "program helps students plan for college, pay for college, and explore \n",
      "careers. Learn more at cb.org .\n",
      "Suggested Citation:  College Board. 2024. Assessment Framework for the \n",
      "Digital SAT Suite , version 3.01 (August 2024). New Y ork: College Board.\n",
      "© 2024 College Board. College Board, Advanced Placement, AP , BigFuture, Landscape, Pre-AP , SAT, and \n",
      "the acorn logo are registered trademarks of College Board. AP Potential, Bluebook, Connections, PSAT, \n",
      "Skills Insight, Student Search Service, and The\n"
     ]
    }
   ],
   "source": [
    "# Download the PDF using requests\n",
    "url = \"https://satsuite.collegeboard.org/media/pdf/assessment-framework-for-digital-sat-suite.pdf\"\n",
    "\n",
    "response = requests.get(url)\n",
    "pdf_bytes = BytesIO(response.content)\n",
    "\n",
    "print(type(pdf_bytes))\n",
    "\n",
    "text = \"\"\n",
    "pdf_reader = PdfReader(pdf_bytes)\n",
    "for page in pdf_reader.pages:\n",
    "    text += page.extract_text()\n",
    "\n",
    "print(text[0:1000])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0994239d",
   "metadata": {
    "papermill": {
     "duration": 0.008629,
     "end_time": "2025-04-08T02:49:32.666724",
     "exception": false,
     "start_time": "2025-04-08T02:49:32.658095",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "This text data might be too big for the model to contain within the prompt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b99f10d6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-08T02:49:32.685627Z",
     "iopub.status.busy": "2025-04-08T02:49:32.685271Z",
     "iopub.status.idle": "2025-04-08T02:49:34.198663Z",
     "shell.execute_reply": "2025-04-08T02:49:34.197645Z"
    },
    "papermill": {
     "duration": 1.525088,
     "end_time": "2025-04-08T02:49:34.200567",
     "exception": false,
     "start_time": "2025-04-08T02:49:32.675479",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "153273"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client.models.count_tokens(\n",
    "    model=model, contents=text\n",
    ").total_tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29be235e",
   "metadata": {
    "papermill": {
     "duration": 0.008902,
     "end_time": "2025-04-08T02:49:34.218920",
     "exception": false,
     "start_time": "2025-04-08T02:49:34.210018",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Chunk the Parsed PDF\n",
    "In order to use the PDF, we need to \"chunk\" it so bits of relevant information can be accessed at a time. In order to maximize efficiency, a vector search database will be used, as the likelihood that any key words in the question will appear on the SAT is effectively zero. \n",
    "\n",
    "The model will instead be a ReAct agent and figure out what to search up and call that tool as an extension and we will see what happens"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "280e9a40",
   "metadata": {
    "papermill": {
     "duration": 0.008804,
     "end_time": "2025-04-08T02:49:34.236923",
     "exception": false,
     "start_time": "2025-04-08T02:49:34.228119",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Initialize ReAct agent\n",
    "The model will instead be a ReAct agent and figure out what to search up and call that tool as an extension and we will see what happens"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efc4b988",
   "metadata": {
    "papermill": {
     "duration": 0.008765,
     "end_time": "2025-04-08T02:49:34.254616",
     "exception": false,
     "start_time": "2025-04-08T02:49:34.245851",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "do some mathplotlib thingies"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [],
   "dockerImageVersionId": 30918,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 65.530041,
   "end_time": "2025-04-08T02:49:35.083725",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-04-08T02:48:29.553684",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
